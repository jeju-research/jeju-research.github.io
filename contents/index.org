#+TITLE: This is a Test
#+AUTHOR: Holy Frege
#+DESCRIPTION: Org-HTML export made simple.
#+KEYWORDS:  org-mode, export, html, theme, style, css, js, bigblow
#+LANGUAGE:  en
#+OPTIONS:   H:4 toc:t num:1  ^:nil
#+MACRO: color @@html:<font color=></font>@@
#+PROPERTY:  header-args :padline no
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+LATEX_HEADER: \usepackage{kotex}
#+latex_header: \hypersetup{colorlinks=true}
#+MACRO: color @@latex:{\color{}@@@@latex:}@@
* <2021-11-30 Tue>
 #+begin_important
간단히 git을 만들고, web page를 만들었다.

 #+end_important

** MP와 MDP의 차이
#+begin_note
일상 생활에서 MP와 MDP 적용여부를 알 수 있을까?
#+end_note
#+CAPTION: MDP
#+NAME: 
https://raw.githubusercontent.com/jeju-research/jeju-research.github.io/main/img/flipcoin1.png
- 손흥민은 agent로 해서 MDP로 설계할 수 있다.

#+CAPTION: MP or MRP
#+NAME: 
[[https://raw.githubusercontent.com/jeju-research/jeju-research.github.io/main/img/flipcoin2.png]]
- agent인 선수를 고려하지 않고 공만 보자.  공의 경우, MDP를 따르게 할 수 있는가? 할 수 없다. 하지만 MP or MRP를 따를 수 있다. action이 없기 때문이다.
- 공에 action을 주어서, 예를 들면, 동서 남북으로 갈수 있는 action이 있다고 가정하고, 그 값을 0으로 해서 처리할 수 있을까? 즉, 돌이나 공같은 무생물에
  action을 부여할 수 있는가? 없다. action의 값은 random하고 policy로 정해지는데, policy는 확률이라서 모든 action값을 0으로 부여하면 policy가 성립되지 않는다.

#+CAPTION: MP or MRP
#+NAME: 
[[https://raw.githubusercontent.com/jeju-research/jeju-research.github.io/main/img/ship1.png]]
- 종이배는 MP와 MRP를 따르게 설계할 수 있다. Reward와 Transition Matrix를 적용해서 종이배의 다음위치를 예측은 가능하다. 하지만, MDP는 안된다.  모터를 달면 MDP가 가능하다.

#+CAPTION: MDP
#+NAME: 
[[https://raw.githubusercontent.com/jeju-research/jeju-research.github.io/main/img/ship2.png
-  MDP를 적용할 수 있다.

